<!DOCTYPE html><html lang="zh-Hans" class="loading"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,minimum-scale=1,maximum-scale=1,user-scalable=no"><title>AnnualRing&#39;blog - Lives affect lives</title><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="google" content="notranslate"><meta name="keywords" content="Annualring,"><meta name="author" content="忆亿亿光年"><link rel="alternative" href="atom.xml" title="AnnualRing&#39;blog" type="application/atom+xml"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><link rel="stylesheet" href="/css/diaspora.css"></head><body class="loading"><div id="loader"></div><div id="single"><div id="top" style="display:block"><div class="bar" style="width:0"></div><a class="icon-home image-icon" href="javascript:;"></a><div title="播放/暂停" class="icon-play"></div><h3 class="subtitle">Realtime Multi-person 2D Pose Estimation using PAF</h3><div class="social"><div><div class="share"><a title="获取二维码" class="icon-scan" href="javascript:;"></a></div><div id="qr"></div></div></div><div class="scrollbar"></div></div><div class="section"><div class="article"><div class="main"><h1 class="title">Realtime Multi-person 2D Pose Estimation using PAF</h1><div class="stuff"> <span>六月 17, 2018</span><ul class="post-tags-list"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/姿态估计/">姿态估计</a></li></ul></div><div class="content markdown"><p class="description"></p><a id="more"></a><h2 id="一-姿态估计一般方法"><a href="#一-姿态估计一般方法" class="headerlink" title="一.姿态估计一般方法"></a>一.姿态估计一般方法</h2><p><strong>自上而下</strong>：就是先检测包含行人的框，即human proposal，然后对框中的人进行姿态估计。</p><p><strong>自下而上</strong>：先检测keypoints，然后根据热力图、点与点之间连接的概率，根据图论知识，基于PAF等将关键点连接起来，再将关键点分组到人。</p><p>本文提出了一种利用Part Affinity Fields（PAFs）的自下而上的人体状态估计算法。这种方法的好处是先得到关键点位置再获得骨架的方法不会随着图像中的人数增加而增加，随着人数的增加，他的计算时间基本不变。</p><h2 id="二-核心思想"><a href="#二-核心思想" class="headerlink" title="二.核心思想"></a>二.核心思想</h2><p><strong>1，使用置信图进行关节检测</strong></p><p>每一个关节对应一个置信图，图像每一个像素点都有一个置信度，置信图中每点的值与ground truth的距离相关。关于多个人的检测，是将K个人的置信图合并取该点每个人的最大值。这里使用最大而不是平均是因为即使峰值很近也不会影响精度。测试阶段使用非极大值抑制来获得身体部分的候选。</p><p><strong>2，使用PAF进行身体部分组合</strong><br>对于多个人的问题，检测了不同人的部分，但是还需要将每个人的身体分别组合在一起形成full-body，使用的方法就是论文的精华PAF。这个方法的好处在于将位置和方向信息都包含了。每一种limb（肢）在关联的两个body part之间都有一个亲和区域，其中的每一个像素都有一个2D 向量的描述方向。亲和<br>区map的维度是w<em>h</em>2 (因为向量是二维的)。若某个点有多人重叠，则将k个人的vector求和，再除以人数。</p><p><strong>3，bottom-up方法</strong><br>在得到了置信图和PAF之后，需要考虑如何利用这些信息找到两两body-part最优化的连接方式，这转换为图论问题。论文使用的是Hungarian algorithm。图中的节点就是body part中的检测候选，边就是这些候选最优的连接方式。每条边上的权值就是亲和区的聚合。因此这样的匹配问题就是找到一组连接使<br>得没有两条边是共享一个节点的，也就是找到权值最大的边连接方式。</p><h2 id="三-网络结构"><a href="#三-网络结构" class="headerlink" title="三.网络结构"></a>三.网络结构</h2><p>输入一幅图像，经过卷积网络提取特征，得到特征图，然后分成两个岔路。</p><p>第一条支路：求所有关键点（头，肩，肘，腕…）</p><ol><li><p>一共两个cnn，第一个cnn输入是原图，输出是热图（每个热图包含某一种关键点）</p></li><li><p>第二个cnn输入是上一个cnn得到的热图还有原图。输出热图。</p><p>循环直至收敛</p></li></ol><p>第二条支路：求所有关节区域</p><ol><li><p>一共两个cnn，第一个cnn的输入是原图，输出是热图（骨头区域，有方向，包含某种连接），它们是一片区域，不过每个地方的概率大小不同。</p></li><li><p>第二个cnn输入是上一个cnn得到的热图还有原图。输出热图。</p><p>循环直至收敛</p></li></ol><p>PAFs是用来描述像素点在骨架中的走向，用L(p)表示；关键点的响应用S(p)表示。先看主体网络结构，网络采用VGG network作为骨架，有两个分支分别回归L(p)和S(p)。每一个stage算一次loss，之后把L和S以及原始输入concatenate，继续下一个stage的训练。随着迭代次数的增加，S能够一定程度上区分结构的左右。loss用的L2范数，S和L的ground-truth需要从标注的关键点生成，如果某个关键点在标注中有缺失则不计算该点。</p><p><img src="http://pb2ovnhbw.bkt.clouddn.com/2018-06-30-TIM%E6%88%AA%E5%9B%BE20180423171307.png" alt=""></p><h2 id="四-获得骨架"><a href="#四-获得骨架" class="headerlink" title="四.获得骨架"></a>四.获得骨架</h2><p>PAFs是用来描述像素点在骨架中的走向，用L表示；关键点的响应用S表示。</p><p>对于S，每一类关键点有一个channel，生成ground-truth的时候按照多个高斯分布区max的方法保留各个点的响应峰值。</p><p>对于L，则复杂一点，先看准定义，对于第k个person的第c个支干上的PAFs：<br>$$<br>L^*_{c,k} = \begin{cases} v, &amp; \text {if p on limb c,k} \ 0, &amp; \text{others} \end{cases}<br>$$</p><p>$$<br>v = (x_{j_2,k}-x_{j_1,k})/||x_{j_2,k}-x_{j_1,k}||_2<br>$$</p><p>$x_{j,k}$表示第k个person的第j个关键点位置。而像素点p是否落在limb上则设了一个阈值范围：<br>$$<br>0\leq v<em>(p - x_{j_1,k}) \leq l_{c,k}and|v_{\bot}</em>(p - x_{j_1,k}) \leq \sigma_l<br>$$<br>其中$l_{c,k}$和$\sigma_l$分别表示limb的长度和宽度。最后也会对所有person相同类别肢干进行平均，使得L的输出的channel与肢干种数相等：<br>$$<br>L^<em>_c (p) = \frac {1}{n_c(p)} \sum_k {L^</em>_{c,k}}(p)<br>$$<br>知道PAFs和关键点位置后（$d_j$），需要评估这俩点的关键性。文章计算了两个关键点连线上各个像素点PAF向量与连线向量的点积的积分：<br>$$<br>E = \int^{u = 1}_{u = 0} {L_c(p(u))} \cdot \frac {d_{j_2} - d_{j_1}}{||d_{j_2} - d_{j_1}||} \,{\rm d}u<br>$$</p><p>$$<br>p(u) = (1-u)d_{j_1} + ud_{j_2}<br>$$</p><p>得到积分、关键点、以及边权后，计算姿态骨架问题就转换为图问题。最后采用匈牙利算法对相邻节点进行了最优匹配（比如一堆左手腕节点和一堆左肘节点，利用小臂的PAF计算边权，再进行最优匹配），最后获得整个人形姿态骨架。</p><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]--><audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="true"><source type="audio/mpeg" src="http://link.hhtjim.com/163/436147067.mp3"></audio></div><div id="gitalk-container" class="comment link" data-ae="true" data-ci="a7bda31026fbce8f09b1" data-cs="493b9d4a6864642efe79e15d0985cdf7e8eacccd" data-r="annualrings.github.io" data-o="annualrings" data-a="annualrings" data-d="true">查看评论</div></div></div></div></div><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",model:{scale:1,hHeadPos:.5,vHeadPos:.618,jsonPath:"/live2dw/assets/assets/koharu.model.json"},display:{superSample:2,width:100,height:250,position:"right",hOffset:150,vOffset:-130},mobile:{show:!1,scale:.1},react:{opacityDefault:.7,opacityOnHover:.2}})</script></body><script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script><script src="/js/plugin.js"></script><script src="/js/diaspora.js"></script><link rel="stylesheet" href="/photoswipe/photoswipe.css"><link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css"><script src="/photoswipe/photoswipe.min.js"></script><script src="/photoswipe/photoswipe-ui-default.min.js"></script><div class="pswp" tabindex="-1" role="dialog" aria-hidden="true"><div class="pswp__bg"></div><div class="pswp__scroll-wrap"><div class="pswp__container"><div class="pswp__item"></div><div class="pswp__item"></div><div class="pswp__item"></div></div><div class="pswp__ui pswp__ui--hidden"><div class="pswp__top-bar"><div class="pswp__counter"></div> <button class="pswp__button pswp__button--close" title="Close (Esc)"></button> <button class="pswp__button pswp__button--share" title="Share"></button> <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button> <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class="pswp__preloader"><div class="pswp__preloader__icn"><div class="pswp__preloader__cut"><div class="pswp__preloader__donut"></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class="pswp__share-tooltip"></div></div> <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button> <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class="pswp__caption"><div class="pswp__caption__center"></div></div></div></div></div></html>